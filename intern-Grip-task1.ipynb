{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79e796a",
   "metadata": {},
   "source": [
    "# GRIP : The Spark Foundation \n",
    "# Data Science & Business Analytics intern\n",
    "# Task 1 :Prediction using Supervised machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a9842",
   "metadata": {},
   "source": [
    "# Author : Rohan Premsingh Negi\n",
    "# Batch : Feb,2022"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50732db9",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce7b7c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours  Scores\n",
       "0    2.5      21\n",
       "1    5.1      47\n",
       "2    3.2      27\n",
       "3    8.5      75\n",
       "4    3.5      30"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AdiPersonalWorks/Random/master/student_scores%20-%20student_scores.csv\")\n",
    "df.head() #Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7d4f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4545aba65e2b433a879fd07489d37348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79009713149f40f8ac140ab6428dccab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc031c517eb648d2b6b5ebdf3a6f33a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pr = ProfileReport(df)\n",
    "Pr.to_widgets()\n",
    "#Detailed dataframe summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d007d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values #splitting into feature and target  \n",
    "y = df.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2a37cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_sc= StandardScaler()   #Standarizing the data set\n",
    "Scaled_X_train = st_sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "165f5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test ,  y_train , y_test = train_test_split(Scaled_X_train,y ,random_state=30 , test_size=.20)\n",
    "#splitting into train test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ec6f6",
   "metadata": {},
   "source": [
    "# creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da285d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr = LinearRegression()\n",
    "Lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c096701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9539008919387528 Test score 0.9452422164650991 for linear regression model\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score {Lr.score(X_train,y_train)} Test score {Lr.score(X_test,y_test)} for linear regression model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "368f8ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=Lr.predict(X_test), y= y_test , ) #for Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87957d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = RandomForestRegressor()\n",
    "rd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0f90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9882126034293864 Test score 0.9169179046185548 for Random forest model\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score {rd.score(X_train,y_train)} Test score {rd.score(X_test,y_test)} for Random forest model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95cbaef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=rd.predict(X_test), y= y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9074c6",
   "metadata": {},
   "source": [
    "# Lets use some hyper parameter tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e2de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = { 'n_estimators': [10,20,40,50,100,110,150,120],\n",
    "    'criterion':[\"mse\", \"mae\"],\n",
    "    'min_samples_split':range(1,10),\n",
    "    'max_features':[\"auto\", \"sqrt\", \"log2\"]   \n",
    "    \n",
    "    \n",
    "    \n",
    "                              }\n",
    "\n",
    "\n",
    "\n",
    "RD = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "357e6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gr = GridSearchCV(estimator= RD , param_grid= Params ,verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd89308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=auto, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=sqrt, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=1, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=2, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=3, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=4, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=5, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=6, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=7, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=8, n_estimators=120; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=20; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=40; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=110; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=150; total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, max_features=log2, min_samples_split=9, n_estimators=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.68662025 0.58768576 0.63495291 0.66440364\n",
      " 0.64943905 0.6691312  0.63627412 0.66972436 0.70839572 0.72762691\n",
      " 0.71191231 0.74335163 0.72994216 0.71999498 0.70277305 0.71867899\n",
      " 0.55152343 0.67528317 0.70979265 0.77559133 0.74127296 0.72121306\n",
      " 0.75474956 0.75334951 0.79863246 0.75942403 0.78167198 0.73262027\n",
      " 0.73837807 0.7259595  0.74389369 0.74384648 0.7359593  0.70242161\n",
      " 0.74804308 0.71844279 0.67799444 0.70904583 0.73525811 0.71319011\n",
      " 0.63766505 0.64705007 0.73498414 0.68962784 0.63978212 0.68368505\n",
      " 0.63944337 0.68956754 0.49975136 0.70602709 0.59715284 0.6197535\n",
      " 0.65671633 0.61291315 0.58612157 0.64467111 0.62246248 0.46617111\n",
      " 0.56539917 0.48859758 0.43433134 0.53681712 0.49406109 0.5292054\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.6344855  0.63593618 0.69303492 0.63287551\n",
      " 0.65138728 0.64686616 0.66338442 0.65310138 0.63172614 0.71638399\n",
      " 0.69284296 0.71070529 0.70180669 0.70319899 0.74086358 0.72620475\n",
      " 0.8104144  0.71523011 0.7148244  0.73046508 0.74116887 0.75346245\n",
      " 0.74235108 0.70975255 0.59752583 0.72445462 0.75698668 0.70265889\n",
      " 0.76726816 0.75937455 0.75017641 0.75314872 0.69431258 0.66711824\n",
      " 0.75434399 0.76006247 0.72697107 0.72427605 0.67508673 0.71055493\n",
      " 0.47997451 0.71357473 0.63799289 0.68271177 0.63930432 0.70411912\n",
      " 0.67319406 0.66518201 0.6428409  0.55129615 0.61466811 0.61331373\n",
      " 0.57727153 0.64745808 0.61033262 0.56757987 0.24103412 0.55554337\n",
      " 0.51197548 0.54971685 0.55926087 0.51178406 0.54702343 0.48292481\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.58342667 0.65931166 0.59096513 0.64890623\n",
      " 0.66283296 0.64893557 0.61869266 0.68693521 0.69549699 0.64942623\n",
      " 0.71175068 0.71429341 0.69185746 0.68715928 0.7021996  0.72012362\n",
      " 0.72081585 0.81695818 0.75064432 0.72506965 0.73885373 0.76097478\n",
      " 0.73491439 0.76196285 0.65954188 0.69198701 0.7537222  0.73710466\n",
      " 0.77861646 0.74573176 0.72286358 0.75655083 0.68976545 0.71156994\n",
      " 0.7178369  0.69305271 0.74335392 0.71839144 0.70951099 0.69113185\n",
      " 0.66580511 0.6412633  0.62984104 0.66342612 0.66385154 0.63842458\n",
      " 0.67723083 0.63091435 0.67173724 0.71116564 0.65423454 0.6099671\n",
      " 0.61843937 0.59086068 0.6296553  0.62781172 0.26306963 0.30896937\n",
      " 0.50548736 0.42110605 0.4250472  0.41875642 0.51869643 0.46351441\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.62810188 0.53194229 0.67088313 0.55580018\n",
      " 0.66468506 0.64097802 0.63573935 0.61204241 0.73507439 0.70920419\n",
      " 0.68593088 0.75716474 0.71733221 0.7515132  0.69203205 0.69435735\n",
      " 0.69795759 0.7181831  0.76258421 0.71392505 0.74994454 0.74720322\n",
      " 0.75909962 0.71677939 0.74523244 0.7171928  0.7155076  0.72766656\n",
      " 0.73704668 0.72645449 0.74105465 0.72589237 0.53217926 0.63473048\n",
      " 0.69052595 0.67519294 0.6976135  0.66468104 0.70505619 0.73042397\n",
      " 0.51052484 0.60684274 0.66756249 0.64811064 0.62379217 0.65268965\n",
      " 0.68676428 0.68481761 0.48656774 0.51041923 0.56276029 0.56226488\n",
      " 0.56632153 0.60744855 0.56293197 0.56689112 0.05194108 0.45631638\n",
      " 0.50184585 0.59124907 0.40578643 0.53526987 0.49469655 0.51429606\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.61273638 0.66739625 0.66086562 0.63327821\n",
      " 0.62728784 0.61766489 0.63374358 0.64278845 0.64516581 0.66158972\n",
      " 0.74129017 0.77309018 0.70743313 0.70486915 0.71298781 0.70014615\n",
      " 0.71735013 0.71128638 0.74454151 0.70803129 0.71277225 0.73054313\n",
      " 0.71988086 0.72501799 0.66500405 0.73742547 0.7919528  0.77845082\n",
      " 0.77691991 0.75370574 0.76499631 0.71675512 0.67687057 0.7008906\n",
      " 0.76688183 0.70809487 0.7427486  0.72069058 0.71963344 0.72700056\n",
      " 0.74655302 0.65596095 0.67817916 0.60679323 0.67986317 0.70669689\n",
      " 0.62037755 0.68327766 0.36789644 0.56783183 0.55883483 0.62694052\n",
      " 0.52872178 0.57713655 0.57569397 0.52494786 0.60182523 0.49423644\n",
      " 0.47831903 0.36190238 0.3037917  0.51550449 0.46762509 0.41083717\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.58369099 0.67025431 0.65427117 0.69075682\n",
      " 0.64682005 0.66239942 0.66779714 0.67405787 0.75186748 0.61135331\n",
      " 0.70625782 0.70485628 0.70557884 0.72807745 0.70828744 0.72033139\n",
      " 0.69573494 0.70410224 0.74119137 0.71286573 0.74239155 0.70301633\n",
      " 0.73905388 0.7413519  0.71219539 0.72009554 0.76194118 0.71934837\n",
      " 0.7720746  0.74957218 0.73756143 0.75301927 0.73671054 0.73650914\n",
      " 0.67127865 0.7053937  0.70857499 0.74548924 0.69104214 0.73590679\n",
      " 0.36666195 0.56276547 0.57931995 0.49266054 0.69365453 0.618305\n",
      " 0.6590278  0.64704162 0.63001847 0.60450291 0.60111629 0.57515285\n",
      " 0.63312624 0.53442124 0.63140901 0.65403326 0.33192725 0.55468297\n",
      " 0.56800118 0.57142356 0.32735879 0.38534238 0.50386316 0.45026117]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(),\n",
       "             param_grid={'criterion': ['mse', 'mae'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_split': range(1, 10),\n",
       "                         'n_estimators': [10, 20, 40, 50, 100, 110, 150, 120]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7288ab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='log2', min_samples_split=4, n_estimators=20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7638d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='log2', min_samples_split=4, n_estimators=20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRR =RandomForestRegressor(max_features='log2', min_samples_split=4, n_estimators=20)\n",
    "GRR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "198e4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9766415819308835 Test score 0.9175046375744934 for Random forest model\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score {GRR.score(X_train,y_train)} Test score {GRR.score(X_test,y_test)} for Random forest model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef54e19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=GRR.predict(X_test), y= y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764829e",
   "metadata": {},
   "source": [
    "# Every model has almost the same r^ for the prediction ,We'll use random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e63edc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.42])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.predict(st_sc.transform([[4.5]])) #Predicting for 4.5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0624c0",
   "metadata": {},
   "source": [
    "# Student's percentage will be 44.42 if he studies for 4.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ec3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
